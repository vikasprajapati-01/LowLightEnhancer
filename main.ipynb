{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2282b5",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66842d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c90438b",
   "metadata": {},
   "source": [
    "Configuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ac9c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TRAIN_IMAGES = 400\n",
    "\n",
    "TRAIN_VAL_IMAGE_DIR = \"data/lol_dataset/our485/low\"\n",
    "TEST_IMAGE_DIR = \"data/lol_dataset/eval15/low\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c1db5c",
   "metadata": {},
   "source": [
    "Dataset accessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "687a71ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Images: 400\n",
      "Number of Validation Images: 85\n",
      "Number of Test Images from LOL Dataset: 15\n"
     ]
    }
   ],
   "source": [
    "train_val_image_files = glob(os.path.join(TRAIN_VAL_IMAGE_DIR, \"*.png\"))\n",
    "test_image_files = glob(os.path.join(TEST_IMAGE_DIR, \"*.png\"))\n",
    "\n",
    "random.shuffle(train_val_image_files)\n",
    "\n",
    "train_image_files = train_val_image_files[:MAX_TRAIN_IMAGES]\n",
    "val_image_files = train_val_image_files[MAX_TRAIN_IMAGES:]\n",
    "\n",
    "print(\"Number of Training Images:\", len(train_image_files))\n",
    "print(\"Number of Validation Images:\", len(val_image_files))\n",
    "print(\"Number of Test Images from LOL Dataset:\", len(test_image_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41d4b98",
   "metadata": {},
   "source": [
    "Data pairing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2f654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d5755de",
   "metadata": {},
   "source": [
    "Preprocessisng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b916babb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9d940a1",
   "metadata": {},
   "source": [
    "Dataset loader class ya function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dee2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5ddfc85",
   "metadata": {},
   "source": [
    "Model Architecture (Convolutional Autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6248fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "838b9e06",
   "metadata": {},
   "source": [
    "Output Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00468274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1889d9ca",
   "metadata": {},
   "source": [
    "Loss function (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e2866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43ae7880",
   "metadata": {},
   "source": [
    "Trainng cofiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780847a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
